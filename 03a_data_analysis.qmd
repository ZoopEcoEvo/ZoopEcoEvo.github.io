---
title: "Data Analysis"
---

The heavy lifting is done via (a series of) data processing scripts, housed within the Scripts directory. This should include any major carpentry (reshaping, organizing, filtering, etc.), along with any intensive statistical analyses. The output of both should be saved to the Outputs directory. **THE RAW DATA SHOULD NEVER BE OVERWRITTEN!** The goal here is to retain the raw data while also reducing the run time / computation power required for data visualization and manuscript prep. As you'll see, both phases are highly iterative (you'll usually knit the same document many times before it's ready to be sent out), and the last thing you'll want is for that process to be bogged down by computationally intensive processes or analyses.

In order to balance the need to retain the raw data and also reduce run times, data processing scripts read in *raw* data and save *processed* data, which can be used downstream for visualizations and other purposes.

# Splitting Scripts 

The same principle can be applied to your data processing scripts; if you've got several different analyses that go into processing your data, and one is really long and computationally intensive, you can split the different processing steps into separate scripts. Once you modify the controller script, you can pick and choose when each processing step should be run.
